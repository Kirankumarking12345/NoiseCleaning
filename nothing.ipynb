{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nothing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhhOT/hQ/V+vq3QZyJ89Vd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kirankumarking12345/NoiseCleaning/blob/main/nothing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQt7vXlFsOLc",
        "outputId": "a9716aa0-4cd0-46b0-caee-ce039feec2b3"
      },
      "source": [
        "!pip install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://google-coral.github.io/py-repo/\n",
            "Requirement already satisfied: tflite_runtime in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tflite_runtime) (1.19.5)\n",
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/a6/53/d78dc063216e62fc55f6b2eebb447f6a4b0a59f55c8406376f76bf959b08/pydub-0.25.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkZVP814qgPA"
      },
      "source": [
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import time\n",
        "import os"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzOQLltFt4qb",
        "outputId": "17845dd8-5d3e-4217-8f5c-4053a337d913"
      },
      "source": [
        "#Converting audio into .wav and downsample by 16kHz\n",
        "def audio2wav(audio_path,output_name):\n",
        "    \"\"\"\n",
        "    Convert any audio format to wav format, need to install ffmpeeg\n",
        "    \"\"\"\n",
        "    output_name=output_name+'.wav'\n",
        "    os.system(\"ffmpeg -i \"+ audio_path+ \" -ac 1 -ar 16000\"+\" \" + output_name )\n",
        "    return k\n",
        " \n",
        "output_file_name='noisechecking' # It must be same name as input\n",
        "path= input(\"Enter the file location: \")\n",
        "i = audio2wav(path,output_file_name)\n",
        "k = path[0:-4]+'.wav'"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter the file location: /content/noisechecking.m4a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28N3zMXZsS-Z",
        "outputId": "2c5b9dc8-0b4f-43a8-ea79-9e2b514c2d8a"
      },
      "source": [
        "\"\"\"\n",
        "This is an example how to implement real time processing of the DTLN tf light\n",
        "model in python.\n",
        "Please change the name of the .wav file at line 43 before running the sript.\n",
        "For .whl files of the tf light runtime go to: \n",
        "    https://www.tensorflow.org/lite/guide/python\n",
        "    \n",
        "Author: Nils L. Westhausen (nils.westhausen@uol.de)\n",
        "Version: 30.06.2020\n",
        "This code is licensed under the terms of the MIT-license.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "##########################\n",
        "# the values are fixed, if you need other values, you have to retrain.\n",
        "# The sampling rate of 16k is also fix.\n",
        "block_len = 512\n",
        "block_shift = 128\n",
        "# load models\n",
        "interpreter_1 = tflite.Interpreter(model_path='/content/pretrained_models/model_1.tflite')\n",
        "interpreter_1.allocate_tensors()\n",
        "interpreter_2 = tflite.Interpreter(model_path='/content/pretrained_models/model_2.tflite')\n",
        "interpreter_2.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details_1 = interpreter_1.get_input_details()\n",
        "output_details_1 = interpreter_1.get_output_details()\n",
        "\n",
        "input_details_2 = interpreter_2.get_input_details()\n",
        "output_details_2 = interpreter_2.get_output_details()\n",
        "# create states for the lstms\n",
        "states_1 = np.zeros(input_details_1[1]['shape']).astype('float32')\n",
        "states_2 = np.zeros(input_details_2[1]['shape']).astype('float32')\n",
        "# load audio file at 16k fs (please change)\n",
        "audio,fs = sf.read(k)\n",
        "# check for sampling rate\n",
        "if fs != 16000:\n",
        "    raise ValueError('This model only supports 16k sampling rate.')\n",
        "# preallocate output audio\n",
        "out_file = np.zeros((len(audio)))\n",
        "# create buffer\n",
        "in_buffer = np.zeros((block_len)).astype('float32')\n",
        "out_buffer = np.zeros((block_len)).astype('float32')\n",
        "# calculate number of blocks\n",
        "num_blocks = (audio.shape[0] - (block_len-block_shift)) // block_shift\n",
        "time_array = []      \n",
        "# iterate over the number of blcoks  \n",
        "for idx in range(num_blocks):\n",
        "    start_time = time.time()\n",
        "    # shift values and write to buffer\n",
        "    in_buffer[:-block_shift] = in_buffer[block_shift:]\n",
        "    in_buffer[-block_shift:] = audio[idx*block_shift:(idx*block_shift)+block_shift]\n",
        "    # calculate fft of input block\n",
        "    in_block_fft = np.fft.rfft(in_buffer)\n",
        "    in_mag = np.abs(in_block_fft)\n",
        "    in_phase = np.angle(in_block_fft)\n",
        "    # reshape magnitude to input dimensions\n",
        "    in_mag = np.reshape(in_mag, (1,1,-1)).astype('float32')\n",
        "    # set tensors to the first model\n",
        "    interpreter_1.set_tensor(input_details_1[1]['index'], states_1)\n",
        "    interpreter_1.set_tensor(input_details_1[0]['index'], in_mag)\n",
        "    # run calculation \n",
        "    interpreter_1.invoke()\n",
        "    # get the output of the first block\n",
        "    out_mask = interpreter_1.get_tensor(output_details_1[0]['index']) \n",
        "    states_1 = interpreter_1.get_tensor(output_details_1[1]['index'])   \n",
        "    # calculate the ifft\n",
        "    estimated_complex = in_mag * out_mask * np.exp(1j * in_phase)\n",
        "    estimated_block = np.fft.irfft(estimated_complex)\n",
        "    # reshape the time domain block\n",
        "    estimated_block = np.reshape(estimated_block, (1,1,-1)).astype('float32')\n",
        "    # set tensors to the second block\n",
        "    interpreter_2.set_tensor(input_details_2[1]['index'], states_2)\n",
        "    interpreter_2.set_tensor(input_details_2[0]['index'], estimated_block)\n",
        "    # run calculation\n",
        "    interpreter_2.invoke()\n",
        "    # get output tensors\n",
        "    out_block = interpreter_2.get_tensor(output_details_2[0]['index']) \n",
        "    states_2 = interpreter_2.get_tensor(output_details_2[1]['index']) \n",
        "    \n",
        "    \n",
        "    # shift values and write to buffer\n",
        "    out_buffer[:-block_shift] = out_buffer[block_shift:]\n",
        "    out_buffer[-block_shift:] = np.zeros((block_shift))\n",
        "    out_buffer  += np.squeeze(out_block)\n",
        "    # write block to output file\n",
        "    out_file[idx*block_shift:(idx*block_shift)+block_shift] = out_buffer[:block_shift]\n",
        "    time_array.append(time.time()-start_time)\n",
        "    \n",
        "# write to .wav file \n",
        "sf.write('out.wav', out_file, fs) \n",
        "print('Processing Time [ms]:')\n",
        "print(np.mean(np.stack(time_array))*1000)\n",
        "print('Processing finished.')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing Time [ms]:\n",
            "0.4514632649486698\n",
            "Processing finished.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez1bGFp4wG5x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}